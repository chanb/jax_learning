{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3ba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import gym\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from argparse import Namespace\n",
    "from flax import linen as nn\n",
    "from jax import grad, jit, vmap, random\n",
    "\n",
    "from jax_learning.buffers.ram_buffers import NextStateNumPyBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68d3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = {\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 3e-4,\n",
    "    \"max_timesteps\": 1000000,\n",
    "    \"memory_size\": 1000000,\n",
    "    \"env\": \"MountainCar-v0\",\n",
    "    \"seed\": 0,\n",
    "}\n",
    "cfg = Namespace(**cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502213a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chanb/work/personal_research/jax_learning/.venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(cfg.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47429e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.act_dim = (env.action_space.n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6009a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.obs_dim = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5b9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.h_state_dim = (1,)\n",
    "cfg.rew_dim = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa83ac68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=128, lr=0.0003, max_timesteps=1000000, memory_size=1000000, env='MountainCar-v0', seed=0, act_dim=(3,), obs_dim=(2,), h_state_dim=(1,), rew_dim=(1,), rng=RandomState(MT19937) at 0x113D26C40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.rng = np.random.RandomState(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfdeb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chanb/work/personal_research/jax_learning/jax_learning/buffers/ram_buffers.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._checkpoint_idxes = np.ones(shape=memory_size, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "buffer = NextStateNumPyBuffer(\n",
    "    memory_size=cfg.memory_size,\n",
    "    obs_dim=cfg.obs_dim,\n",
    "    h_state_dim=cfg.h_state_dim,\n",
    "    act_dim=cfg.act_dim,\n",
    "    rew_dim=cfg.rew_dim,\n",
    "    rng=cfg.rng,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact(policy, buffecfg):\n",
    "    max_timesteps = cfg.max_timesteps\n",
    "    \n",
    "    obs = env.reset()\n",
    "    for timestep_i in range(max_timesteps):\n",
    "        act = policy(obs)\n",
    "        next_obs, rew, done, info = env.step(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = random.normal(key,(4,))\n",
    "print(\"Original v:\")\n",
    "print(v)\n",
    "print(\"Gradient of f taken at point v\")\n",
    "print(jax.grad(f)(v)) # should be equal to v !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b573bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, x):\n",
    "  return jnp.dot(x, W) + b\n",
    "\n",
    "# Loss function: Mean squared error.\n",
    "def mse(W, b, x_batched, y_batched):\n",
    "  # Define the squared loss for a single pair (x,y)\n",
    "  def squared_error(x, y):\n",
    "    y_pred = predict(W, b, x)\n",
    "    return jnp.inner(y-y_pred, y-y_pred) / 2.0\n",
    "  # We vectorize the previous to compute the average of the loss on all samples.\n",
    "  return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set problem dimensions.\n",
    "n_samples = 20\n",
    "x_dim = 10\n",
    "y_dim = 5\n",
    "\n",
    "# Generate random ground truth W and b.\n",
    "key = random.PRNGKey(0)\n",
    "k1, k2 = random.split(key)\n",
    "W = random.normal(k1, (x_dim, y_dim))\n",
    "b = random.normal(k2, (y_dim,))\n",
    "\n",
    "# Generate samples with additional noise.\n",
    "key_sample, key_noise = random.split(k1)\n",
    "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
    "y_samples = predict(W, b, x_samples) + 0.1 * random.normal(key_noise,(n_samples, y_dim))\n",
    "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize estimated W and b with zeros.\n",
    "W_hat = jnp.zeros_like(W)\n",
    "b_hat = jnp.zeros_like(b)\n",
    "\n",
    "# Ensure we jit the largest-possible jittable block.\n",
    "@jax.jit\n",
    "def update_params(W, b, x, y, lr):\n",
    "  W, b = W - lr * jax.grad(mse, 0)(W, b, x, y), b - lr * jax.grad(mse, 1)(W, b, x, y)\n",
    "  return W, b\n",
    "\n",
    "learning_rate = 0.3  # Gradient step size.\n",
    "print('Loss for \"true\" W,b: ', mse(W, b, x_samples, y_samples))\n",
    "for i in range(101):\n",
    "  # Perform one gradient update.\n",
    "  W_hat, b_hat = update_params(W_hat, b_hat, x_samples, y_samples, learning_rate)\n",
    "  if (i % 5 == 0):\n",
    "    print(f\"Loss step {i}: \", mse(W_hat, b_hat, x_samples, y_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c67435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
