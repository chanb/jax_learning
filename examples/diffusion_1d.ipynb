{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1ad97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import optax\n",
    "\n",
    "from jax_learning.losses.supervised_loss import squared_loss\n",
    "from jax_learning.models.layers import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bcf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005625d",
   "metadata": {},
   "source": [
    "# Noise Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9adc5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = jnp.array((0.1, 0.1, 0.1))\n",
    "alphas = 1 - betas\n",
    "alpha_cum_prods = jnp.cumprod(alphas)\n",
    "\n",
    "sqrt_alpha_cumprods = jnp.sqrt(alpha_cum_prods)\n",
    "sqrt_one_minus_alpha_cumprods = jnp.sqrt(1 - alpha_cum_prods)\n",
    "\n",
    "def add_noise(x_init: np.ndarray, noise: np.ndarray, t: np.int32):\n",
    "    return sqrt_alpha_cumprods[t, None] * x_init + sqrt_one_minus_alpha_cumprods[t, None] * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facdebdb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6544f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(eqx.Module):\n",
    "    obs_dim: int = eqx.static_field()\n",
    "    model: eqx.Module\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: Sequence[int],\n",
    "        context_dim: Sequence[int],\n",
    "        hidden_dim: int,\n",
    "        num_hidden: int,\n",
    "        key: jrandom.PRNGKey,\n",
    "    ):\n",
    "        self.obs_dim = obs_dim\n",
    "        self.model = MLP(self.obs_dim + context_dim + 1, self.obs_dim, hidden_dim, num_hidden, key)\n",
    "        \n",
    "    @jax.jit\n",
    "    def predict(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        t: float,\n",
    "    ) -> np.ndarray:\n",
    "        x_t = jnp.concatenate((x, jnp.array([t])))\n",
    "        return self.model(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89baf9",
   "metadata": {},
   "source": [
    "# Download MNIST\n",
    "Reference: https://github.com/hsjeong5/MNIST-for-Numpy/blob/master/mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4124ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading MNIST dataset\n",
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/qs8bwp4d7bg67j4vbv960hdh0000gn/T/ipykernel_28818/1219993782.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_x = train_x.astype(np.float) / 255\n",
      "/var/folders/h6/qs8bwp4d7bg67j4vbv960hdh0000gn/T/ipykernel_28818/1219993782.py:49: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_x = test_x.astype(np.float) / 255\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def download_mnist():\n",
    "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "    for name in filename:\n",
    "        print(\"Downloading \"+name[1]+\"...\")\n",
    "        request.urlretrieve(base_url+name[1], name[1])\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def save_mnist():\n",
    "    mnist = {}\n",
    "    for name in filename[:2]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "    for name in filename[-2:]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    with open(\"mnist.pkl\", 'wb') as f:\n",
    "        pickle.dump(mnist,f)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "def init():\n",
    "    download_mnist()\n",
    "    save_mnist()\n",
    "\n",
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "if not os.path.isfile(\"mnist.pkl\"):\n",
    "    init()\n",
    "    \n",
    "print(\"loading MNIST dataset\")\n",
    "(train_x, train_y, test_x, test_y) = load()\n",
    "train_x = train_x.astype(np.float) / 255\n",
    "test_x = test_x.astype(np.float) / 255\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93778cbe",
   "metadata": {},
   "source": [
    "# DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cf89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_grad(has_aux=True)\n",
    "def compute_loss(model: Model, xs: np.ndarray, timesteps: np.ndarray, targs: np.ndarray):\n",
    "    preds = jax.vmap(model.predict)(xs, timesteps)\n",
    "    loss = jnp.sum(jax.vmap(squared_loss)(preds, targs)) / len(xs)\n",
    "    return loss, {\"loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c738e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_x: np.ndarray,\n",
    "    train_c: np.ndarray,\n",
    "    model: Model,\n",
    "    opt: optax.GradientTransformation,\n",
    "    cfg: Namespace\n",
    ") -> Tuple[Model, List]:\n",
    "    \"\"\"\n",
    "    train_x: data to reconstruct\n",
    "    train_c: data context\n",
    "    model: the diffusion model\n",
    "    opt: optimizer for changing the parameters of the model\n",
    "    \"\"\"\n",
    "    opt_state = opt.init(model)\n",
    "    losses = []\n",
    "    \n",
    "    for i in tqdm(range(cfg.num_iterations)):\n",
    "        train_idxes = np.random.permutation(len(train_x))[:cfg.batch_size]\n",
    "        curr_c = train_c[train_idxes]\n",
    "        curr_x = train_x[train_idxes]\n",
    "        timesteps = np.random.randint(cfg.max_t, size=cfg.batch_size)\n",
    "        \n",
    "        noise = np.random.randn(*curr_x.shape)\n",
    "        noisy_x = add_noise(curr_x, noise, timesteps)\n",
    "        noisy_x = jnp.concatenate((noisy_x, curr_c[:, None]), axis=1)\n",
    "        grads, info = compute_loss(model, noisy_x, timesteps, noise)\n",
    "        updates, opt_state = opt.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        losses.append(info[\"loss\"])\n",
    "        \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb5577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████▋                                                | 6897/50000 [03:03<18:59, 37.82it/s]"
     ]
    }
   ],
   "source": [
    "obs_dim = int(np.product(train_x.shape[1:]))\n",
    "context_dim = 1\n",
    "hidden_dim = 256\n",
    "num_hidden = 4\n",
    "key = jrandom.PRNGKey(seed)\n",
    "\n",
    "model = Model(obs_dim, context_dim, hidden_dim, num_hidden, key)\n",
    "\n",
    "lr = 3e-4\n",
    "opt_transforms = [optax.scale_by_rms(), optax.scale(-lr)]\n",
    "opt = optax.chain(*opt_transforms)\n",
    "\n",
    "cfg_dict = {\n",
    "    \"num_iterations\": 50000,\n",
    "    \"batch_size\": 512,\n",
    "    \"max_t\": 20,\n",
    "}\n",
    "cfg = Namespace(**cfg_dict)\n",
    "\n",
    "trained_model, losses = train(train_x, train_y, model, opt, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b59848",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.xlabel(\"Number of updates\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trained_model.predict(jnp.concatenate((np.random.randn(*test_x[0].shape), test_y[[0]])), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred.reshape((28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290933bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
