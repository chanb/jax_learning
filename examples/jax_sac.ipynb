{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3ba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import gym\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import optax\n",
    "import sys\n",
    "import timeit\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from jax import grad, jit, vmap\n",
    "from typing import Sequence, Tuple, Optional\n",
    "\n",
    "from jax_learning.buffers.ram_buffers import NextStateNumPyBuffer\n",
    "from jax_learning.buffers.utils import batch_flatten, to_jnp\n",
    "from jax_learning.constants import DISCRETE, CONTINUOUS\n",
    "from jax_learning.rl_utils import interact, evaluate\n",
    "\n",
    "from jax_learning.models import Policy, ActionValue, MLP, StochasticPolicy, Model\n",
    "from jax_learning.models.policies import MLPSquashedGaussianPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a46b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"test_jax_rl\", group=\"reacher-sac_test\")\n",
    "wandb.define_metric(\"episodic_return\", summary=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = {\n",
    "    # Environment setup\n",
    "    \"env\": \"Reacher-v2\",\n",
    "    \"seed\": 0,\n",
    "    \"render\": False,\n",
    "    \n",
    "    # Experiment progress\n",
    "    \"load_step\": 0,\n",
    "    \"log_interval\": 5000,\n",
    "    \n",
    "    # Learning hyperparameters\n",
    "    \"max_timesteps\": 1000000,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"buffer_warmup\": 1000,\n",
    "    \"num_gradient_steps\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_grad_norm\": 10.,\n",
    "    \"gamma\": 0.99,\n",
    "    \"update_frequency\": 4,\n",
    "    \n",
    "    # Actor\n",
    "    \"actor_lr\": 3e-4,\n",
    "    \"actor_update_frequency\": 1,\n",
    "    \n",
    "    # Critic\n",
    "    \"critic_lr\": 3e-4,\n",
    "    \"target_update_frequency\": 1,\n",
    "    \"tau\": 0.005, # This is for polyak averaging of target network\n",
    "    \n",
    "    # Temperature\n",
    "    \"alpha_lr\": 3e-4,\n",
    "    \"init_alpha\": 1.0,\n",
    "    \"target_entropy\": \"auto\",\n",
    "    \n",
    "    # Model architecture\n",
    "    \"hidden_dim\": 256,\n",
    "    \"num_hidden\": 2,\n",
    "    \n",
    "    # Evaluation\n",
    "    \"eval_cfg\": {\n",
    "        \"max_episodes\": 100,\n",
    "        \"seed\": 1,\n",
    "        \"render\": True,\n",
    "    }\n",
    "}\n",
    "cfg = Namespace(**cfg_dict)\n",
    "eval_cfg = Namespace(**cfg.eval_cfg)\n",
    "wandb.config = cfg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502213a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(cfg.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.obs_dim = env.observation_space.shape\n",
    "cfg.act_dim = env.action_space.shape\n",
    "cfg.action_space = CONTINUOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.h_state_dim = (1,)\n",
    "cfg.rew_dim = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a581441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.buffer_rng = np.random.RandomState(cfg.seed)\n",
    "cfg.env_rng = np.random.RandomState(cfg.seed)\n",
    "cfg.agent_key, cfg.model_key = jrandom.split(jrandom.PRNGKey(cfg.seed), num=2)\n",
    "eval_cfg.env_rng = np.random.RandomState(eval_cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd356a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_learning.models.q_functions import MLPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db4ed7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "obs_dim, act_dim, hidden_dim, num_hidden, keys = (1,), (1,), 2, 2, jrandom.split(jrandom.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc64fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ActionValue.__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qs \u001b[38;5;241m=\u001b[39m [MLPSoftmaxQ(obs_dim, act_dim, hidden_dim, num_hidden, key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys]\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qs \u001b[38;5;241m=\u001b[39m [\u001b[43mMLPSoftmaxQ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys]\n",
      "File \u001b[0;32m~/work/personal_research/jax_learning/.venv/lib/python3.10/site-packages/equinox/module.py:131\u001b[0m, in \u001b[0;36m_ModuleMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__class__\u001b[39m\u001b[38;5;124m\"\u001b[39m, initable_cls)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__class__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/work/personal_research/jax_learning/jax_learning/models/q_functions.py:76\u001b[0m, in \u001b[0;36mMLPSoftmaxQ.__init__\u001b[0;34m(self, obs_dim, act_dim, hidden_dim, num_hidden, key)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m              obs_dim: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     71\u001b[0m              act_dim: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     72\u001b[0m              hidden_dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     73\u001b[0m              num_hidden: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     74\u001b[0m              key: jrandom\u001b[38;5;241m.\u001b[39mPRNGKey):\n\u001b[1;32m     75\u001b[0m     SoftmaxQ\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs_dim, act_dim)\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mMLPQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/personal_research/jax_learning/jax_learning/models/q_functions.py:22\u001b[0m, in \u001b[0;36mMLPQ.__init__\u001b[0;34m(self, obs_dim, act_dim, hidden_dim, num_hidden, key)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     17\u001b[0m              obs_dim: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     18\u001b[0m              act_dim: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     19\u001b[0m              hidden_dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     20\u001b[0m              num_hidden: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     21\u001b[0m              key: jrandom\u001b[38;5;241m.\u001b[39mPRNGKey):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobs_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_function \u001b[38;5;241m=\u001b[39m MLP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_dim, hidden_dim, num_hidden, key)\n",
      "\u001b[0;31mTypeError\u001b[0m: ActionValue.__init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "qs = [MLPSoftmaxQ(obs_dim, act_dim, hidden_dim, num_hidden, key) for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQ(ActionValue):\n",
    "    obs_dim: int\n",
    "    act_dim: int\n",
    "    qs: Sequence[ActionValue]\n",
    "\n",
    "    def __init__(self,\n",
    "                 obs_dim: Sequence[int],\n",
    "                 act_dim: Sequence[int],\n",
    "                 qs: Sequence[ActionValue]):\n",
    "        self.obs_dim = int(np.product(obs_dim))\n",
    "        self.act_dim = int(np.product(act_dim))\n",
    "        self.qs = qs\n",
    "\n",
    "    def q_values(self,\n",
    "                 obs: np.ndarray,\n",
    "                 h_state: np.ndarray,\n",
    "                 act: Optional[np.ndarray]=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        q_vals, h_states = jax.vmap(Model.apply_function, in_axes=[0, None, None, None])(self.qs, obs, h_state, act)\n",
    "        return q_vals, h_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MultiQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, static = eqx.partition(model, filter_spec=lambda x: isinstance(x, MLP))\n",
    "print(type(params))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b558a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_learning.learners import LearnerWithTargetNetwork\n",
    "class SAC(LearnerWithTargetNetwork):\n",
    "    def __init__(self,\n",
    "                 model: eqx.Module,\n",
    "                 target_model: eqx.Module,\n",
    "                 opt: optax.GradientTransformation,\n",
    "                 buffer: ReplayBuffer,\n",
    "                 cfg: Namespace):\n",
    "        super().__init__(model, target_model, opt, buffer, cfg)\n",
    "        \n",
    "        self._step = cfg.load_step\n",
    "        self._batch_size = cfg.batch_size\n",
    "        self._num_gradient_steps = cfg.num_gradient_steps\n",
    "        self._gamma = cfg.gamma\n",
    "        \n",
    "        self._buffer_warmup = cfg.buffer_warmup\n",
    "        self._update_frequency = cfg.update_frequency\n",
    "        self._actor_update_frequency = cfg.actor_update_frequency\n",
    "        self._target_update_frequency = cfg.target_update_frequency\n",
    "        self._tau = cfg.tau\n",
    "        self._omega = cfg.omega\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72cdf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "buffer = NextStateNumPyBuffer(\n",
    "    buffer_size=cfg.buffer_size,\n",
    "    obs_dim=cfg.obs_dim,\n",
    "    h_state_dim=cfg.h_state_dim,\n",
    "    act_dim=(1,) if cfg.action_space == DISCRETE else cfg.act_dim,\n",
    "    rew_dim=cfg.rew_dim,\n",
    "    rng=cfg.buffer_rng,\n",
    ")\n",
    "\n",
    "model = MLPSoftmaxQ(obs_dim=cfg.obs_dim,\n",
    "                    act_dim=cfg.act_dim,\n",
    "                    hidden_dim=cfg.hidden_dim,\n",
    "                    num_hidden=cfg.num_hidden,\n",
    "                    key=cfg.model_key)\n",
    "\n",
    "target_model = MLPSoftmaxQ(obs_dim=cfg.obs_dim,\n",
    "                           act_dim=cfg.act_dim,\n",
    "                           hidden_dim=cfg.hidden_dim,\n",
    "                           num_hidden=cfg.num_hidden,\n",
    "                           key=cfg.model_key)\n",
    "\n",
    "opt = optax.chain(\n",
    "    optax.clip_by_global_norm(cfg.max_grad_norm),  # Clip by the gradient by the global norm\n",
    "    optax.scale_by_adam(),  # Use the updates from adam\n",
    "    optax.scale(-1.0) # Gradient descent\n",
    ")\n",
    "\n",
    "learner = QLearning(model=model,\n",
    "                    target_model=target_model,\n",
    "                    opt=opt,\n",
    "                    buffer=buffer,\n",
    "                    cfg=cfg)\n",
    "\n",
    "agent = EpsilonGreedyAgent(model=model,\n",
    "                           buffer=buffer,\n",
    "                           learner=learner,\n",
    "                           init_eps=cfg.init_eps,\n",
    "                           min_eps=cfg.min_eps,\n",
    "                           eps_decay=cfg.eps_decay,\n",
    "                           eps_warmup=cfg.eps_warmup,\n",
    "                           key=cfg.agent_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d3924",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00043b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(env, agent, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32851f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(env, agent, eval_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7794fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.roll(buffer.next_observations, 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116971b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((buffer.observations - np.roll(buffer.next_observations, 1, axis=0), buffer.dones), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f03ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.sample_with_next_obs(3, buffer.next_observations[19], buffer.hidden_states[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
