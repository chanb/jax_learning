{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import optax\n",
    "import timeit\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "\n",
    "from jax_learning.agents.rl_agents import EpsilonGreedyAgent, RLAgent\n",
    "from jax_learning.buffers.ram_buffers import TrajectoryNumPyBuffer\n",
    "from jax_learning.common import init_wandb\n",
    "from jax_learning.constants import DISCRETE, CONTINUOUS\n",
    "from jax_learning.rl_utils import interact, evaluate, random_exploration_generator\n",
    "from jax_learning.learners.path_consistency import PCL\n",
    "from jax_learning.models import Temperature\n",
    "from jax_learning.models.policies import MLPSquashedGaussianPolicy, MLPGaussianPolicy\n",
    "from jax_learning.models.value_functions import MLPValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a46b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be \"online\", \"offline\" or \"disabled\".\n",
    "init_wandb(project=\"test_jax_rl\", group=\"hopper-pcl_test\", mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = {\n",
    "    # Environment setup\n",
    "    \"env\": \"Hopper-v2\",\n",
    "    \"seed\": 0,\n",
    "    \"render\": False,\n",
    "    # Experiment progress\n",
    "    \"load_step\": 0,\n",
    "    \"log_interval\": 5000,\n",
    "    # Learning hyperparameters\n",
    "    \"max_timesteps\": 1000000,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"buffer_warmup\": 1000,\n",
    "    \"num_gradient_steps\": 1,\n",
    "    \"batch_size\": 32,\n",
    "    \"max_grad_norm\": False,\n",
    "    \"gamma\": 0.99,\n",
    "    \"update_frequency\": 1,\n",
    "    \"exploration_steps\": 0,\n",
    "    \"exploration_strategy\": \"standard_gaussian\",\n",
    "    # Actor\n",
    "    \"actor_lr\": 3e-4,\n",
    "    # Critic\n",
    "    \"critic_lr\": 3e-4,\n",
    "    # Rollout\n",
    "    \"horizon_length\": 20,\n",
    "    # Epsilon greedy hyperparameters\n",
    "    \"init_eps\": 1.0,\n",
    "    \"min_eps\": 0.02,\n",
    "    \"eps_decay\": 0.9,\n",
    "    \"eps_warmup\": 1000,\n",
    "    # Normalization\n",
    "    \"normalize_obs\": False,\n",
    "    \"normalize_value\": False,\n",
    "    # Temperature\n",
    "    \"alpha_lr\": 3e-4,\n",
    "    \"init_alpha\": 1.0,\n",
    "    \"target_entropy\": -3,\n",
    "    # Model architecture\n",
    "    \"hidden_dim\": 256,\n",
    "    \"num_hidden\": 2,\n",
    "    # Evaluation\n",
    "    \"evaluation_frequency\": 5000,\n",
    "    \"eval_cfg\": {\n",
    "        \"num_episodes\": 10,\n",
    "        \"seed\": 1,\n",
    "        \"render\": False,\n",
    "        \"clip_action\": True,\n",
    "        \"max_action\": 1.0,\n",
    "        \"min_action\": -1.0,\n",
    "    },\n",
    "}\n",
    "cfg = Namespace(**cfg_dict)\n",
    "eval_cfg = Namespace(**cfg.eval_cfg)\n",
    "wandb.config = cfg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502213a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(cfg.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.obs_dim = env.observation_space.shape\n",
    "cfg.act_dim = env.action_space.shape\n",
    "if cfg.target_entropy == \"auto\":\n",
    "    cfg.target_entropy = -float(np.product(env.action_space.shape))\n",
    "cfg.action_space = CONTINUOUS\n",
    "\n",
    "cfg.random_exploration = None\n",
    "if getattr(cfg, \"exploration_steps\", False):\n",
    "    cfg.random_exploration = random_exploration_generator(\n",
    "        cfg.exploration_strategy,\n",
    "        cfg.act_dim,\n",
    "        getattr(cfg, \"min_action\", -1.0),\n",
    "        getattr(cfg, \"max_action\", 1.0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.h_state_dim = (1,)\n",
    "cfg.rew_dim = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3591254",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.buffer_rng = np.random.RandomState(cfg.seed)\n",
    "cfg.env_rng = np.random.RandomState(cfg.seed)\n",
    "cfg.agent_key, cfg.model_key = jrandom.split(jrandom.PRNGKey(cfg.seed), num=2)\n",
    "eval_cfg.env_rng = np.random.RandomState(eval_cfg.seed)\n",
    "cfg.evaluation_cfg = eval_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a581441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72cdf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "POLICY = \"policy\"\n",
    "Q = \"q\"\n",
    "V = \"v\"\n",
    "TEMPERATURE = \"temperature\"\n",
    "\n",
    "buffer = TrajectoryNumPyBuffer(\n",
    "    buffer_size=cfg.buffer_size,\n",
    "    obs_dim=cfg.obs_dim,\n",
    "    h_state_dim=cfg.h_state_dim,\n",
    "    act_dim=(1,) if cfg.action_space == DISCRETE else cfg.act_dim,\n",
    "    rew_dim=cfg.rew_dim,\n",
    "    rng=cfg.buffer_rng,\n",
    ")\n",
    "\n",
    "policy_key, v_key = jrandom.split(cfg.model_key)\n",
    "policy = MLPGaussianPolicy(\n",
    "    obs_dim=cfg.obs_dim,\n",
    "    act_dim=cfg.act_dim,\n",
    "    hidden_dim=cfg.hidden_dim,\n",
    "    num_hidden=cfg.num_hidden,\n",
    "    key=policy_key,\n",
    ")\n",
    "# policy = MLPSquashedGaussianPolicy(\n",
    "#         obs_dim=cfg.obs_dim,\n",
    "#         act_dim=cfg.act_dim,\n",
    "#         hidden_dim=cfg.hidden_dim,\n",
    "#         num_hidden=cfg.num_hidden,\n",
    "#         key=policy_key,\n",
    "# )\n",
    "\n",
    "temperature = Temperature(init_alpha=cfg.init_alpha)\n",
    "\n",
    "v = MLPValue(\n",
    "    in_dim=cfg.obs_dim,\n",
    "    out_dim=(1,),\n",
    "    hidden_dim=cfg.hidden_dim,\n",
    "    num_hidden=cfg.num_hidden,\n",
    "    key=v_key,\n",
    ")\n",
    "\n",
    "model = {\n",
    "    POLICY: policy,\n",
    "    TEMPERATURE: temperature,\n",
    "    V: v,\n",
    "}\n",
    "\n",
    "v_opt_transforms = [optax.scale_by_adam(), optax.scale(-cfg.critic_lr)]\n",
    "\n",
    "policy_opt_transforms = [optax.scale_by_adam(), optax.scale(-cfg.actor_lr)]\n",
    "\n",
    "temperature_opt_transforms = [optax.scale_by_adam(), optax.scale(-cfg.alpha_lr)]\n",
    "\n",
    "if cfg.max_grad_norm:\n",
    "    v_opt_transforms.insert(0, optax.clip_by_global_norm(cfg.max_grad_norm))\n",
    "    policy_opt_transforms.insert(0, optax.clip_by_global_norm(cfg.max_grad_norm))\n",
    "    temperature_opt_transforms.insert(0, optax.clip_by_global_norm(cfg.max_grad_norm))\n",
    "opt = {\n",
    "    V: optax.chain(*v_opt_transforms),\n",
    "    POLICY: optax.chain(*policy_opt_transforms),\n",
    "    TEMPERATURE: optax.chain(*temperature_opt_transforms),\n",
    "}\n",
    "\n",
    "learner = PCL(model=model, opt=opt, buffer=buffer, cfg=cfg)\n",
    "\n",
    "# agent = RLAgent(\n",
    "#     model=model, model_key=POLICY, buffer=buffer, learner=learner, key=cfg.agent_key\n",
    "# )\n",
    "\n",
    "agent = EpsilonGreedyAgent(\n",
    "    model=model,\n",
    "    model_key=POLICY,\n",
    "    buffer=buffer,\n",
    "    learner=learner,\n",
    "    init_eps=cfg.init_eps,\n",
    "    min_eps=cfg.min_eps,\n",
    "    eps_decay=cfg.eps_decay,\n",
    "    eps_warmup=cfg.eps_warmup,\n",
    "    action_space=CONTINUOUS,\n",
    "    action_dim=cfg.act_dim[0],\n",
    "    key=cfg.agent_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d3924",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00043b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(env, agent, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f03ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
